\chapter{CÁC CÔNG TRÌNH LIÊN QUAN}

\section{Những phương pháp biểu diễn khu vực}

Định vị trực quan được định nghĩa là một bài toán xác định vị trí của ảnh chụp. Nhằm giúp mô hình có thể định vị được trong một khu vực lớn, đa phần các phương pháp sẽ cần một cách để biểu diễn khu vực đang xét. Đa số các tập dữ liệu thường được xây dựng sử dụng ảnh 2D. Điều này là nhờ vào sự phát triển của công nghệ camera, giúp ảnh 2D có thể được thu thập một cách dễ dàng. Những tập dữ liệu ảnh 2D chỉ mang thông tin về màu sắc của cảnh vật, dưới định dạng RGB. Ngoài ra, một số tập dữ liệu đề xuất việc sử dụng ảnh RGBD, chứa cả thông tin về màu và độ sâu của ảnh, nhằm biểu diễn rõ ràng hơn cảnh vật.

\subsection{Đặc trưng của ảnh}

Do số lượng ảnh bên trong tập dữ liệu có kích thước rất lớn, vậy nên đa số những tác vụ thao tác trên ảnh trong tập dữ liệu sẽ sử dụng những đặc trưng, một cách biểu diễn tối ưu hơn của ảnh. Đặc trưng ảnh là những điểm ảnh mang nhiều thông tin như góc, cạnh, giúp thể hiện khung cảnh trong ảnh mà không bị thay đổi khi thay đổi góc quay. Một đặc trưng ảnh sẽ được xác định vị trí rồi được sinh ra mô tả cho những đặc điểm trực quan tại vị trí đó. Những mô tả này sẽ cần phải có giá trị ổn định khi gặp những điều kiện như thay đổi về độ chiếu sáng, góc quay và thay đổi tỷ lệ phóng to, thu nhỏ.

\subsection{Ảnh RGB}

Ảnh RGB là tập hợp các điểm ảnh có chiều cao và chiều rộng nhất định. Mỗi điểm ảnh sẽ được thể hiện bằng một vector ba biến nhất định thể hiện cho ba màu. Màu của một điểm ảnh sẽ là sự kết hợp của ba màu đỏ, xanh lá, xanh dương với cường độ của mỗi màu sẽ được thể hiện qua vector tại điểm ảnh đó. Ảnh RGB được sinh ra từ việc ánh sáng tiếp xúc với tập hợp những cảm biến trong camera, từ đó xác định được cường độ của các màu.

Chính vì cấu tạo của chúng nên ảnh RGB sẽ không thể biểu diễn được không gian 3D mà chỉ xác định được hướng của những sự vật trong hình so với camera. Tuy nhiên, ảnh RGB lại có thể được thu thập một cách dễ dàng từ rất nhiều loại camera, dẫn đến những tập dữ liệu RGB phổ biến và được sử dụng phổ biến. Ngoài ra, để bổ sung thêm thông tin về không gian 3D cho ảnh RGB, một số giải thuật phức tạp, cần nhiều tài nguyên tính toán, cũng như yêu cầu nhiều hình có thể được sử dụng.

Một mô hình sử dụng ảnh RGB chỉ có thể trích xuất những đặc trưng bên trong ảnh và cần sử dụng biểu diễn của khu vực để có được thông tin từ không gian 3D.

\subsection{Ảnh RGBD}

So với ảnh RGB, ảnh RGBD sẽ không những chỉ rõ màu sắc và hướng chiếu đến camera của vật mà còn cho biết khoảng cách giữa camera và vật. Mỗi điểm ảnh RGBD sẽ có một vector gồm 4 biến, 3 biến màu và một biến thể hiện độ sâu vật thể tại điểm đó so với camera. Ảnh RGBD được sinh ra với cơ chế thu ánh sáng như ảnh RGB thông thường với thông tin về độ sâu thu được từ các cảm biến tích hợp vào.

Thông tin thêm về độ sâu sẽ giúp ảnh phản ánh đúng hơn môi trường không gian 3D trong khung hình. Tuy nhiên, để đo được độ sâu của ảnh, một số cảm biến chuyên dụng cần được sử dụng. Hiện tại, có tổng cộng 4 phương pháp đo độ sâu bằng là sử dụng công nghệ chiếu rọi 3D, cảm biến ToF, cảm biến LiDAR và đa camera \cite{lopes2022survey}.
\begin{itemize}
    \item Phương pháp chiếu rọi 3D dựa trên việc một chùm sáng gồm một loạt các mẫu hình dáng với hình dạng, kích thước tính toán sẵn lên vật thể. Sau đó, ánh sáng phản chiếu từ vật sẽ được thu bởi nhiều camera để tính toán độ sâu dựa vào phép đạc tam giác.
    \item Cảm biến ToF sẽ tính được độ sâu từ camera đến ảnh dựa trên thời gian cần thiết để một sóng ánh sáng đi tới vật thể và phản xạ về lại cảm biến.
    \item Cảm biến LiDAR cũng sẽ đo thời gian phản xạ của ánh sáng như cảm biến ToF, tuy nhiên tia laser sẽ được sử dụng thay thế cho ánh sáng thông thường. Chùm tia laser sẽ được chiếu 360 độ và các xung phản xạ sẽ được đo bằng cảm biến nhằm sinh ra một bản đồ điểm 3D.
    \item Phương pháp đa camera sử dụng phép đạc tam giác để xác định độ sâu của một điểm trong không gian thực khi biết được vị trí của điểm đó ở trong ảnh của mỗi camera, khoảng cách giữa hai camera và thông số kỹ thuật của mỗi camera.
\end{itemize}

Với ảnh RGBD, thông tin của không gian 3D đã được tích hợp sẵn trong ảnh. Điều này giúp cung cấp thêm dữ liệu cho mô hình, nhằm đưa ra kết quả chính xác hơn. Cụ thể như qua việc xác định được vị trí của những đặc trưng của ảnh trong không gian 3D trong quá trình huấn luyện mô hình \cite{brachmann2021visual,arnold2022mapfree}.


\subsection{Kết luận}
Ảnh RGBD cung cấp thêm thông tin về độ sâu của những vật thể bên trong ảnh đang xét, giúp biểu diễn không gian 3D bên trong mô hình một cách chính xác hơn. Nhờ vậy nên những mô hình ứng dụng ảnh RGBD như DSAC* \cite{brachmann2021visual} sẽ có độ chính xác cao so với những phương pháp sử dụng ảnh RGB thuần. Để cạnh tranh với ảnh RGBD, những phương pháp sử dụng ảnh RGB sẽ cần phải suy ra thông tin về độ sâu, sẽ được đề cập kỹ hơn trong phần sau. Tuy nhiên, một giới hạn của ảnh RGBD chính là những khó khăn trong việc thu thập dữ liệu. Ảnh RGBD sẽ cần những thiết bị đặc thù, giá thành cao để thu thập, dẫn đến việc mô hình bị giới hạn trong những khu vực có thể ứng dụng được. Ngược lại, ảnh RGB có thể được sinh ra từ nhiều loại máy ảnh, từ camera điện thoại, camera hành trình cho đến camera chuyên dụng. Vì vậy, để có thể phát triển một mô hình có thể được ứng dụng ở nhiều khu vực khác nhau, chúng tôi hướng đến việc sử dụng ảnh RGB trong mô hình được đề xuất.

\section{Những phương pháp đã được sử dụng}

Cho đến hiện tại, nhiều hướng tiếp cận cho bài toán định vị trực quan đã được đề xuất. Những phương pháp quan trọng nhất có thể được nhóm vào hai nhóm chính là \textbf{Những phương pháp sử dụng biểu diễn 3D} và \textbf{Những phương pháp hồi quy tư thế}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{pics/Chapter2/overviewViLoc.png}
    \caption{Tổng quát về những phương pháp định vị trực quan quan trọng \cite{methodsLocal}}
\end{figure}

\subsection{Những phương pháp sử dụng biểu diễn 3D}
\subsubsection*{Ý tưởng}
Những phương pháp sử dụng biểu diễn 3D hoạt động xoay quanh việc tái tạo lại môi trường đang xét bằng một bản đồ đám mây điểm 3D. Bản đồ 3D chứa những đặc trưng trích xuất được từ các ảnh, tiến hành tìm kiếm các cặp đặc trưng tương quan giữa các ảnh với nhau nhằm tạo thành những điểm mô tả 3D trong không gian ba chiều. Những bản đồ này thường sẽ được mô hình tạo ra tại giai đoạn tiền xử lý tập dữ liệu và sẽ được dùng trong suốt quá trình định vị của mô hình.
\subsubsection*{Những bước thực hiện}
\begin{itemize}
    \item Ở bước tiền xử lý, không gian được thể hiện bởi tập dữ liệu sẽ được tái tạo lại trong không gian 3D, sử dụng những ảnh cùng thể hiện một cảnh, nhưng từ những vị trí và góc nhìn khác nhau. Phương pháp này được gọi là 'Tái tạo kiến trúc từ chuyển động' - Structure from Motion (SfM). Cụ thể hơn, quá trình này sẽ gồm các giai đoạn:
          \begin{itemize}
              \item Trích xuất mô tả của các đặc trưng từ ảnh: Mỗi ảnh trong tập dữ liệu sẽ được trích xuất đặc trưng và mỗi đặc trưng sẽ được gán một giá trị mô tả để SfM có thể tìm được những đặc trưng tương đồng giữa các hình. Kết quả trả về sẽ là một tập các mô tả cho đặc trưng của từng ảnh.
              \item Tìm kiếm sự tương quan của các đặc trưng giữa các ảnh: SfM sẽ tìm kiếm những ảnh cùng nhìn bộ phận của cảnh bằng cách kiểm tra sự tương đồng giữa các mô tả của đặc trưng trên các ảnh. Những cặp ảnh chứa những cặp đặc trưng tương quan sẽ cần được xác nhận lại về tính đúng đắn hình học qua việc liệu có tồn tại một cách biến đổi có khả năng ánh xạ một số lượng trưng giữa hai ảnh.
              \item Tái tạo lại cấu trúc: Quá trình tái tạo lại cấu trúc sẽ bắt đầu từ một cặp ảnh khởi tạo. Sau đó, không gian điểm 3D sẽ dần được mở rộng khi các ảnh được thêm tuần tự qua giải thuật PnP trong vòng lặp RANSAC.
          \end{itemize}
    \item Sau khi có được bản đồ đám mây điểm 3D biểu diễn môi trường đang xét, những đặc trưng trong ảnh nhận vào sẽ được trích xuất và so sánh mô tả của chúng với những điểm trong bản đồ 3D của khu vực. Khi những cặp đặc trưng 2D-3D đã được xác định, giải thuật PnP trong vòng lặp RANSAC sẽ được sử dụng một lần nữa để xác định vị trí của ảnh được chụp.
\end{itemize}
\subsubsection*{Những biến thể của phương pháp}

Một trong những tác vụ quan trọng nhất trong bài toán định vị bằng biểu diễn 3D chính là việc trích xuất được đặc trưng của ảnh và tạo cách mô tả thích hợp cho chúng. Ở những phương pháp truyền thống, những giải thuật được định nghĩa thủ công như SIFT \cite{lowe2004distinctive} và SURF \cite{bay2006surf} thường được sử dụng. Tuy nhiên, ở những giải thuật này tồn tại một số điểm yếu, xuất phát từ việc chúng không được thiết kế đặc biệt cho tác vụ hiện tại là truy xuất những ảnh biểu diễn cảnh giống nhau. Điều này làm giảm hiệu quả, đặc biệt trong điều kiện thay đổi như ngày-đêm hay thay đổi theo mùa. Trong khoảng thời gian gần đây, những hướng tiếp cận theo hướng học sâu đã được đề xuất, chủ yếu sử dụng mạng CNN để trích xuất và biểu diễn đặc trưng. Những cách tiếp cận này vẫn gặp khó khăn trong việc nhận biết được những đặc điểm hình học trong hình \cite{zhou2020learn}.

Để có thể biểu diễn chính xác được một thành phố lớn trong không gian 3D, một lượng lớn điểm 3D sẽ cần được sử dụng. Với tập dữ liệu Aachen Day-Night \cite{sattler2018benchmarking}, mô hình 3D sẽ có số lượng điểm dao động từ 700 nghìn cho đến 2.5 triệu, tùy thuộc vào số lượng cặp ảnh được dùng: chiến lược tìm kiếm Brute-Force dần trở nên bất khả thi khi môi trường biểu diễn trở nên lớn hơn. Để giới hạn lại không gian tìm kiếm, chiến lược truy xuất ảnh đã được sử dụng để tìm kiếm ảnh trong tập dữ liệu tương đồng nhất với ảnh truy vấn. Sau đó, việc tìm kiếm tương quan sẽ chỉ diễn ra trong không gian được thể hiện bởi những ảnh đó \cite{sarlin2019coarse}.

Để không phải lưu trữ một bản đồ 3D cho toàn bộ khu vực đang xét, một phương pháp được đề xuất là xây dựng bản đồ điểm 3D cục bộ. Thay vì sinh ra bản đồ 3D cho toàn bộ khu vực đang xét ở bước tiền xử lý, phương pháp này sẽ sử dụng những ảnh truy xuất được để sinh ra bản đồ cục bộ \cite{sattler2017large}. Phương pháp này có thể tận dụng được những điểm mạnh của việc sử dụng cách biểu diễn 3D mà không cần duy trì bản đồ điểm 3D của toàn bộ khu vực. Tuy nhiên, cách tiếp cận này vẫn có một số điểm yếu như việc thời gian thực thi tăng đáng kể và số lượng ảnh truy xuất được có thể chưa đủ để sinh ra một bản đồ 3D phù hợp.

Một cách tiếp cận khác với mục tiêu loại bỏ sự cần thiết của bản đồ 3D, sử dụng mạng học sâu để xác định được vị trí của một điểm ảnh trong môi trường 3D, gọi là hồi quy điểm trong cảnh - Scene Point Regression \cite{brachmann2021visual}. Tuy nhiên, những mô hình thuộc phương pháp này không có tính khái quát hóa cao và để có thể thực thi trên một khu vực nhất định thì mô hình cần dữ liệu mẫu thuộc khu vực đó để huấn luyện.
\subsubsection*{Phân tích ưu và nhược điểm của phương pháp}
Nhờ vào việc sử dụng cách biểu diễn trong không gian 3D mà lớp phương pháp này đã thành công học được tính hình học của môi trường, dẫn đến kết quả của lớp phương pháp này thường đạt độ chính xác tương đối cao. Ngoài ra, lớp phương pháp này sử dụng điểm 3D trong không gian làm mốc để định vị. Nhờ vậy nên mô hình vẫn sẽ cho ra được kết quả tốt khi không gian mẫu của vị trí chụp của ảnh bị giới hạn.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.7]{pics/Chapter2/lim.png}
    \caption[Kịch bản so sánh phương pháp 3D và phương pháp sử dụng biểu diễn ngầm \cite{sattler2019understanding}]{Kịch bản khi mà tập dữ liệu huấn luyện bị hạn chế. Quỹ đạo của tập huấn luyện và tập kiểm thử có màu \textcolor{red}{đỏ} và \textcolor{green}{xanh lá}. Kết quả của những mô hình lấy vị trí của ảnh làm mốc là PoseNet \cite{kendall2016posenet} và MapNet \cite{brahmbhatt2018geometryaware} có quỹ đạo kết quả màu \textcolor{blue}{xanh dương} và \textcolor{purple}{tím}. Kết quả của phương pháp sử dụng biểu diễn 3D là Active Search \cite{sattler2016efficient} có quỹ đạo màu \textcolor{cyan}{xanh lam}. Hình được lấy từ \cite{sattler2019understanding}}
\end{figure}

Đa số những vấn đề xoay quanh lớp phương pháp này liên quan đến việc sinh ra, lưu trữ và sử dụng biểu diễn 3D của khu vực. Do những bản đồ 3D biểu diễn những khu vực lớn sẽ cần rất nhiều điểm 3D, dẫn đến việc tiêu tốn nhiều tài nguyên tính toán để sinh ra và sử dụng cũng như cần nhiều bộ nhớ để lưu trữ. Ngoài ra, đánh đổi cho khả năng biểu diễn một khu vực với độ chi tiết cao, những mô hình sử dụng cách biểu diễn 3D sẽ mất khả năng khái quát hóa khi xử lý những ảnh bên ngoài khu vực đang xét và cần phải được huấn luyện lại trên tập dữ liệu khác.

\subsection{Những phương pháp hồi quy tư thế}
\subsubsection*{Ý tưởng}

Trong khi những phương pháp truy xuất ảnh ngày càng phát triển về độ chính xác, độ chính xác của các hướng tiếp cận này bị giới hạn ở vị trí của ảnh truy vấn mà không thể trả về vị trí chính xác của ảnh đầu vào. Một hướng tiếp cận khác, với mục tiêu trả về trực tiếp vị trí và hướng quay của ảnh đầu vào, đã ra đời và được tập trung phát triển khá nhiều trong thời gian gần đây - Hồi quy tư thế máy ảnh.

\subsubsection*{Những bước thực hiện}

Hồi quy tư thế thường được chia thành hai hướng tiếp cận chính: hồi quy tư thế tuyệt đối và hồi quy tư thế tương đối. Tuy nhiên, nhìn chung một phương pháp hồi quy tư thế sẽ thường có những bước sau:
\begin{itemize}
	\item Trích xuất những đặc trưng, chi tiết có thông tin bên trong ảnh hoặc cặp ảnh.
	\item Tiến hành mã hóa hình thành một tập các giá trị đại diện. Trong những năm gần đây, hướng tiếp cận sử dụng Vision Transformer đã đem lại hiệu quả hơn so với những mô hình CNN thông thường.
	\item Ánh xạ tới cách biểu diễn phù hợp: Những giá trị mã hóa của một ảnh có thể được dùng để ánh xạ trực tiếp ra những cách biểu diễn đã được định nghĩa từ trước hoặc dùng để tính toán độ chênh lệch giữa cặp ảnh.
\end{itemize}

\subsubsection*{Những biến thể của phương pháp}

Hồi quy tư thế tuyệt đối là nhóm phương pháp dùng mô hình học sâu để trực tiếp tính toán ra tư thế (vị trí, góc quay) của ảnh đầu vào. PoseNet \cite{kendall2016posenet} là một phương pháp đặc trưng cho hướng tiếp cận này. Những mô hình CNN cơ sở như VGGNet hoặc ResNet sẽ được loại bỏ lớp Softmax cuối cùng và được thay thế bằng những lớp kết nối đầy đủ để trích xuất đặc trưng ảnh, sau đó các mô-đun khác của mô hình sẽ tiến hành tổng hợp đặc trưng vừa được trích xuất rồi xác định được vị trí và góc quay của ảnh thông qua nhiều ý tưởng khác nhau. Đã có nhiều ý tưởng cải thiện được đề xuất cho hướng tiếp cận này như việc giới thiệu một hàm mất mát mới, áp dụng những lớp mạng trích xuất tốt hơn (LSTM, Vision Transformer,\dots) \cite{keetha2023anyloc} hoặc tích hợp thêm dữ liệu từ cảm biến như ngữ nghĩa của cảnh, độ sâu của cảnh \cite{yan2022crossloc}, hướng quay của vật bên trong hình \cite{liu2019lending} \dots

Nhóm phương pháp hồi quy tư thế tương đối không xác định tư thế thiết bị chụp ảnh một cách trực tiếp, mà nhờ vào việc tính toán độ lệch giữa ảnh truy vấn với một ảnh tham khảo đã biết trước tư thế. Các bước thực hiện bao gồm hai bước là truy xuất ảnh nhằm thu được ảnh tham khảo có độ tương đồng gần nhất với ảnh nhận vào, và xác định độ lệch vị trí và góc quay giữa cặp ảnh thông qua nhiều phương pháp khác nhau. Phương pháp này có thể được cải thiện khi áp dụng những mô hình cơ sở có khả năng trích xuất tốt hơn \cite{shavit2023coarse}. Ngoài ra, nếu như những thông số của máy ảnh được cung cấp, độ lệch về vị trí và góc quay của cặp ảnh có thể được xác định từ việc tìm kiếm cặp đặc trưng tương quan giữa hai hình từ ma trận thiết yếu \cite{zhou2020learn}. Một số mô hình hồi quy tư thế tương đối chọn cách sử dụng mạng học sâu nhằm tính toán tư thế, trong khi một số mô hình lại chọn cách áp dụng các giải thuật, các mô hình cơ sở nhằm thực thi tác vụ này.

\subsubsection*{Phân tích ưu và nhược điểm của phương pháp}
Với những mô hình hồi quy tư thế chọn cách sử dụng mạng học sâu: những mạng nơ-ron học sâu thường có thể khám phá được những cách trích xuất hiệu quả hơn, hoạt động tốt hơn trong những điều kiện thay đổi như ngày-đêm, các mùa trong năm. Ngoài ra, quá trình xử lý dữ liệu của các mô hình sử dụng mạng học sâu sẽ yêu cầu ít hơn về tài nguyên và có thời gian thực thi ngắn hơn do không còn các bước xử lý giữa. Vì vậy, với việc tận dụng các mạng học sâu, nhóm phương pháp hồi quy tư thế máy ảnh đã có thể tận dụng được những mô hình CNN đã cho ra kết quả tốt trong những tác vụ thị giác máy tính khác làm mô hình cơ sở.

Tuy nhiên, việc ứng dụng những mô hình học sâu cũng có một số điểm yếu. Đa số các mô hình hồi quy đầu-cuối hiện tại chỉ thí nghiệm trên những tập dữ liệu trong phạm vi nhỏ và có sự phân bố ảnh dày đặc tại mỗi vị trí. Ngoài ra, độ chính xác của những phương pháp hồi quy cũng sẽ không thể bằng được so với phương pháp sử dụng biểu diễn 3D do những mô hình CNN cơ sở vẫn còn gặp khó khăn trong việc học được những thông tin hình học \cite{zhou2020learn}. Môi trường đang xét cũng được biểu diễn ngầm trong những trọng số của mô hình, làm mất đi khả năng khái quát hóa tới khu vực khác của mô hình \cite{sattler2019understanding}.

Với những mô hình hồi quy tư thế tương đối chọn cách áp dụng các mô hình cơ sở kết hợp các thuật toán nhằm tính toán tư thế, kết quả của các mô hình theo hướng tiếp cận này thường đạt độ chuẩn xác cao hơn so với việc sử dụng mô hình học sâu. Ngoài ra, hướng tiếp cận này không phụ thuộc vào quá trình huấn luyện, dẫn tới giảm thiểu tài nguyên và không bị giảm đi hiệu quả khi hoạt động trên dữ liệu mới. Tuy nhiên, hướng tiếp cận này vẫn có một số khuyết điểm cần cân nhắc: thời gian thực thi thường cao hơn so với các mô hình đầu-cuối, các mô hình cơ sở riêng lẻ ở các bước có thể hoạt động không hiệu quả,...

\subsection{Kết luận}
Hướng tiếp cận sử dụng cách biểu diễn 3D có kết quả vượt trội hơn hẳn. Tuy nhiên, để đánh đổi cho độ chính xác này, nhóm phương pháp này đã mất đi tính khái quát hóa cho những tập dữ liệu khác, cũng như tiêu tốn một lượng tài nguyên lớn để khởi tạo và duy trì bản đồ 3D. Hướng tiếp cận hồi quy tư thế tuyệt đối cũng gặp phải vấn đề tương tự về khả năng khái quát hóa thấp cùng với đó độ chính xác chưa đủ tốt.

Nhằm hướng đến một giải pháp có khả năng có thể áp dụng được trên nhiều môi trường khác nhau mà không phụ thuộc quá nhiều vào quá trình huấn luyện, chúng tôi đã chọn phát triển phương pháp theo hướng kết hợp truy xuất ảnh và hồi quy tư thế tương đối với mục tiêu xây dựng một mô hình với kết quả cạnh tranh mà không tiêu tốn quá nhiều tài nguyên, cả về bộ nhớ cũng như tính toán.

Một giải pháp hoàn chỉnh sẽ bao gồm hai thành phần là \textbf{nhận diện địa điểm trực quan} và \textbf{hồi quy tư thế tương đối}. Ở những phần sau, những giải pháp đã được đề xuất trong hai lĩnh vực này sẽ được khảo sát.


\input{chapters/related-works/vpr/index.tex}

\section{Ước tính vị trí của máy ảnh - Pose Estimation}

Ước tính vị trí máy ảnh (Camera Pose Estimation) là một bài toán thuộc chuyên ngành thị giác máy tính nhằm xác định vị trí (position) và góc quay (orientation) chính xác nhất có thể của máy ảnh thông qua dữ liệu hình ảnh được chụp từ chính máy ảnh. Đây là một bước cực kỳ quan trọng trong việc giải quyết bài toán định vị trực quan, thường được áp dụng sau khi bước nhận diện địa điểm trực quan hoặc truy xuất ảnh đã trích xuất được ảnh từ cơ sở dữ liệu. Một trong những phương pháp phổ biến nhất cho tác vụ này là huấn luyện một mô hình học sâu để xác định 6 chiều tự do (Degree of Freedom) từ số ít ảnh (Absoblute Pose Regression và Relative Pose Regression).

\subsection{Hồi quy tư thế tuyệt đối - Absolute Pose Regression}

Hồi quy tư thế tuyệt đối (Absolute Pose Regression) hướng đến việc dự đoán vị trí và góc quay chính xác nhất của ảnh bằng một mô hình CNN học sâu thông qua việc cải thiện trọng số của mô hình. Tùy thuộc vào đầu vào của mô hình mà hồi quy tư thế tuyệt đối được chia thành ba hướng chính: hồi quy tư thế tuyệt đối với một ảnh, chuỗi ảnh hoặc đoạn phim.

\subsubsection*{Hồi quy tư thế tuyệt đối đơn ảnh - Absolute pose regression through single monocular image}
Với phương pháp hồi quy tư thế tuyệt đối thông qua một ảnh, quy trình chung thường bao gồm: đầu vào - mạng - đầu ra. Đầu vào sẽ là một ảnh RGB với đầu ra là vị trí 6 DoF của máy ảnh. Thông thường, kiến trúc của mạng lưới tính toán sẽ bao gồm các thành phần như sau: bộ mã hóa, bộ định vị, bộ hồi quy.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{pics/Chapter2/kientruc_APR_1.png}
    \caption{Kiến trúc mô hình hồi quy tư thế tuyệt đối đơn ảnh \cite{kendall2016posenet}}
\end{figure}

\noindent\textbf{Phương pháp sử dụng hàm mất mát Euclidean cố định:}

PoseNet \cite{kendall2016posenet} là công trình đầu tiên huấn luyện mô hình CNN để hồi quy tư thế máy ảnh từ một ảnh RGB, hoàn toàn không phụ thuộc vào bất kỳ cơ chế bên ngoài nào khác. Vào thời điểm ra mắt, PoseNet đã cho thấy độ vững chắc của mô hình vượt trội so với phương pháp tái tạo kiến trúc từ chuyển động dựa trên cơ chế "biến đổi tính năng bất biến tỷ lệ" (Scale-invariant Feature Transform Structure from Motion): độ hiệu quả của kiến trúc vế sau giảm mạnh nếu độ lớn của tập dữ liệu huấn luyện giảm đến một mức nhất định. Hàm mất mát Euclidean của PoseNet được định nghĩa như sau:
\begin{center}
    $loss(I) = \left \| \hat{x} - x \right \|_2 + \beta \left \| \hat{q} - \frac{q}{\left \| q \right \|} \right \|_2$
\end{center}

Kế thừa từ PoseNet, đã có nhiều công trình và bài báo tìm cách cải thiện phương pháp định vị hoặc thay thế hàm mất mát nhằm nâng cao hiệu suất chung của toàn kiến trúc. Với các công trình có mong muốn cải thiện hàm mất mát của mô hình, một chiến thuật chung là kết hợp hàm mất mát Euclidean và phương pháp giảm độ dốc Stochastic. Về mặt cải thiện hiệu quả định vị cũng như tìm hiểu về độ thiếu chính xác của mô hình, một nhóm tác giả đề xuất thêm xác suất Bernoulli vào mô hình nơ-ron tích chập \cite{kendall2016modelling} nhằm xác định độ thiếu chính xác của mô hình. Ý tưởng chính của phương pháp này là xác định và tận dụng độ thiếu chính xác để dự đoán sai số trong định vị, phương pháp này đã cải thiện độ chính xác cho PoseNet cho cả những cảnh ngoài trời và bên trong nhà.

\noindent\textbf{Phương pháp sử dụng hàm mất mát có trọng số học được:}

Để học được thông tin về vị trí và góc quay từ dữ liệu ảnh, hàm mất mát cố định Euclidean áp dụng các siêu tham số cân bằng để giúp việc học thông tin vị trí và góc quay một cách độc lập, tuy nhiên để học trọng số thì rất tốn kém. Geometric PoseNet \cite{kendall2017geometric} đề xuất sử dụng hàm mất mát vị trí có trọng số học được để cân bằng hiệu suất và cải thiện độ ổn định. Khi so sánh với PoseNet, phương pháp này giữ lại độ mở rộng và độ chắc chắn mà không cần chỉnh sửa các siêu tham số cố định cân bằng trong hàm mất mát.

AtLoc \cite{wang2019atloc} thêm vào mô hình một mô-đun tập trung (Attention Module) trước khi xác định các tọa độ hồi quy để  buộc mạng phải tập trung vào phần mang nhiều thông tin hữu ích nhất của hình ảnh đầu vào. Ngoài ra, AtLoc sử dụng ResNet34 được huấn luyện sẵn trên tập dữ liệu ImageNet làm bộ mã hóa, sau đó hồi quy lớp kết nối đầy đủ 2048 chiều của PoseNet.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{pics/Chapter2/atloc.png}
    \caption{Minh họa kiến trúc mô hình AtLoc \cite{wang2019atloc}}
\end{figure}

\noindent\textbf{Phương pháp sử dụng hàm mất mát khác:}

Không dùng đến cả hàm mất mát cố định hoặc những hàm mất mát có trọng số học được, một số nhóm nghiên cứu đề xuất sử dụng bổ sung các mô-đun khác để cải thiện hiệu suất định vị. GPoseNet \cite{Cai2018AHP} xây dựng mô hình mới bằng cách thêm vào hai bộ "Hồi quy quá trình Gaussian suy luận biến phân ngẫu nhiên" (Stochastic Variational Inference Gaussian Process Regressions - SVI GPs) sau lớp kết nối đầy đủ để học phân phối xác suất của vị trí - hướng quay đầu ra và giảm tần suất sử dụng siêu tham số. Hàm mất mát của GPoseNet kết hợp hàm mất mát SVI GPs sử dụng ranh giới điều kiện dưới của hai xác suất tích lũy log $L_{s}vi$ và hàm mất mát CNN với siêu tham số $\beta_{g_{t}}$ và $\beta_{n_{q}}$ của PoseNet.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{pics/Chapter2/gposenet.png}
    \caption{Minh họa kiến trúc mô hình GPoseNet \cite{kendall2017geometric}}
\end{figure}

Một nhóm nghiên cứu \cite{shavit2021learning, shavit2023coarse} đề xuất áp dụng mô hình Transformer vào tác vụ hồi quy tư thế tuyệt đối. Mô hình nhận vào một ảnh đơn và sử dụng một CNN làm bộ trích xuất đặc trưng, sau đó các bản đồ đặc trưng được truyền song song qua hai nhánh: mỗi nhánh là một mô hình Transformer đảm nhiệm một tác vụ riêng lần lượt là hồi quy vị trí và hồi quy hướng quay. Mô hình sử dụng hàm mất mát tương tự với PoseNet.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{pics/Chapter2/trans.png}
    \caption{Minh họa kiến trúc mô hình Multi-Scene Transformer \cite{shavit2021learning, shavit2023coarse}}
\end{figure}

\subsubsection*{Hồi quy tư thế tuyệt đối đa ảnh - Absolute pose regression through auxiliary image sequence}
Một phương pháp khác được áp dụng để hồi quy tư thế tuyệt đối là áp dụng học có hỗ trợ với một chuỗi ảnh. Học có hỗ trợ được định nghĩa là phương pháp cải thiện hiệu suất của một tác vụ chính thông qua việc học cùng lúc các tác vụ hỗ trợ. Phương pháp học này giúp mô hình phát triển các biểu diễn dữ liệu tốt hơn. Bằng cách tận dụng các tác vụ hỗ trợ có liên quan khác trong quá trình học, hiệu suất của tác vụ chính có thể được cải thiện. Ở đây, học có hỗ trợ ám chỉ việc kết hợp APR với các tác vụ phụ có liên quan như đo lường cảm biến trực quan. Hàm mất mát của các phương pháp học có hỗ trợ thường bao gồm hàm mất mát của APR kết hợp với hàm mất mát của các phương pháp phụ trợ, thậm chí có thể kết hợp cả hàm mất mát của APR và RPR. Khác với các phương pháp hồi quy tư thế tuyệt đối đơn ảnh, phương pháp học có hỗ trợ học từ các cặp ảnh với bản chất là học cách xác định tư thế tuyệt đối bằng cách đánh giá trước hết tư thế tương đối với các ràng buộc phụ thuộc.

MapNet \cite{brahmbhatt2018geometryaware} đề xuất sử dụng thêm một thuật ngữ mất mát lấy từ các cặp ảnh làm một ràng buộc hình học, điều này đã có thể cải thiện mạnh mẽ hiệu suất khả năng định vị. Về hàm mất mát, MapNet giảm thiểu tối đa cả mất mát tư thế tuyệt đối cho mỗi hình ảnh và mất mát tư thế tương đối giữa các cặp hình ảnh:
\begin{center}
    $l(I_{total}) = l(I_i) + \alpha\sum_{i\neq j}loss(I_{ij} )$
\end{center}
Trong đó, $loss(I_{ij} )$ chỉ tư thế máy ảnh tương đối $p_i$ và $p_j$ giữa các cặp hình ảnh $I_i$ và $I_j$, được tính bởi hàm mất mát với trọng số có thể học được.

Thêm vào đó, MapNet chuyển một giá trị quaternion thành logarit của giá trị đó - biểu diễn phép quay 3DoF với ba chiều chưa bị tham số hóa quá mức. $logq$ được biểu diễn như dưới đây, với $u$ và $v$ đại diện cho phần thực và ảo của một quaternion đơn vị:
\begin{center}
    $logq =
        \begin{cases}
            \frac{v}{\left \| v \right \|}cos^{-1}u, \left \| v \right \| \neq 0 \\
            0
        \end{cases}$
\end{center}
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{pics/Chapter2/mapnet.png}
    \caption{Minh họa kiến trúc mô hình MapNet \cite{brahmbhatt2018geometryaware}}
\end{figure}

\subsubsection*{Hồi quy tư thế tuyệt đối qua đoạn phim - Absolute pose regression through video}

Không chỉ đơn ảnh hay đa ảnh, ngay cả đoạn phim cũng có thể được sử dụng để thêm một ràng buộc thời gian có tính trơn tru hơn cho hồi quy tư thế. Các đoạn phim hay các dữ liệu cảm biến khác đều có thể được truy cập dễ dàng bởi các thiết bị di động. Đoạn phim có thể được đồng bộ hóa với các dữ liệu đầu vào khác như đo lường cảm biến trực quan, các cảm biến IMU như đồng hồ tăng tốc và đồng hồ quay và dữ liệu GNSS bằng thông tin thời gian , cụ thể là bằng cách căn chỉnh các mốc thời gian. Với một quy trình tương tự như các phương pháp ARP dựa trên hình ảnh đơn và chuỗi hình ảnh, ARP dựa trên đoạn phim cũng hồi quy vị trí và hướng quay thông qua bộ trích xuất đặc trưng là một CNN và bộ hồi quy tư thế cục bộ.
\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\textwidth]{pics/Chapter2/vidloc.png}
    \caption{Minh họa kiến trúc mô hình VidLoc \cite{clark2017vidloc}}
\end{figure}
VidLoc \cite{clark2017vidloc} đề xuất một mô hình hồi quy tư thế máy ảnh dựa trên việc kết hợp CNN – RNN, mục đích là có thể khiến quá trình dự đoán vị trí từ ảnh hay một đoạn phim được trơn tru hơn. Mạng được xây dựng bằng cách sử dụng GoogLeNet Inception \cite{szegedy2014going} mà không dùng đến lớp kết nối đầy đủ để trích xuất đặc trưng ảnh và một mô-đun LSTM hai chiều để mô hình hóa thông tin thời gian với các ô nhớ.  Hàm mất mát của VidLoc được tính bằng tổng của lỗi vị trí và lỗi hướng quay từ đầu ra của LSTM như sau:
\begin{center}
    $ l = \sum_{t=1}^T \alpha_1 \left \| x_t - \hat{x}_t \right \| + \alpha_2 \left \| q_t - \hat{q}_t \right \| $
\end{center}
Với $[x_t, q_t]$ và $[\hat{x}_t, \hat{q}_t]$ đại diện cho sự thật nền tảng và giá trị dự đoán cho độ dời vị trí và hướng quay.

\subsubsection*{Kết luận}
Xét về các phương pháp mang hướng hồi quy tư thế tuyệt đối thông qua một ảnh duy nhất, các nghiên cứu có xu hướng tiến tới việc hàm mất mát tự động hóa, không sử dụng siêu tham số và mang nhiều thông tin hơn để giảm việc sử dụng các tham số cố định. Khởi đầu từ PoseNet với việc sử dụng một hàm mất mát cố định để tính tổng độ dời và hướng quay sử dụng một số tham số cân bằng. Sau đó, một hàm mất mát có trọng số học được \cite{wang2019atloc, bui2019adversarial} đã được đề xuất bằng cách thêm độ không đảm bảo phương sai đồng nhất để tự động cân bằng mất mát độ dời và hướng quay, tránh sử dụng siêu tham số đồng thời vượt qua hiệu suất của phương pháp sử dụng hàm mất mát cố định. Với việc sử dụng nhiều ảnh cũng như học kết hợp các tác vụ phụ, các mô hình đã có thể không chỉ thu được kết quả định vị mà còn có được thông tin khác như VO, thông tin ngữ nghĩa,etc. Cho rằng các phương pháp hồi quy tư thế tuyệt đối thông qua ảnh đang bỏ phí giá trị của các ràng buộc thời gian, một số công trình \cite{clark2017vidloc, brahmbhatt2018geometryaware} đề xuất việc tận dụng các đoạn phim làm đầu vào cho tác vụ hồi quy tư thế. VidLoc \cite{clark2017vidloc} sử dụng RNN hai chiều để hồi quy tư thế 6DoF của máy ảnh.

Nhìn chung, đã có nhiều hướng tiếp cận tương đối sáng tạo và thông minh với hồi quy tư thế tuyệt đối. Điểm tích cực nhất có thể thấy là độ chính xác của các mô hình ngày càng tăng, giải quyết được nhiều thử thách khó khăn hơn trong bài toán định vị hóa trực quan. Tuy nhiên, có thể thấy phần nhiều các mô hình thuộc nhóm hồi quy tư thế tuyệt đối phụ thuộc nhiều vào quá trình huấn luyện, cụ thể là các tập dữ liệu huấn luyện tương đối nhỏ do tài nguyên huấn luyện tiêu hao nhiều, dẫn đến độ khái quát hóa thường không quá cao.

\subsection{Hồi quy tư thế tương đối - Relative Pose Regression}

Khác với hồi quy tư thế tuyệt đối, các phương pháp mang hướng tiếp cận hồi quy tư thế tương đối (Relative Pose Regression) không tính toán trực tiếp tư thế của ảnh đầu vào mà thay vào đó, chỉ tính toán tư thế tương đối của ảnh đầu vào và ảnh tương đồng nhằm dự đoán tư thế tuyệt đối của ảnh đầu vào.

\subsubsection*{Hồi quy tư thế tương đối thông qua truy xuất rõ ràng - Relative camera pose regression through explicit retrieval}
Quy trình hồi quy tư thế tương đối của máy ảnh có thể được hiểu như một quy trình bao gồm truy xuất ảnh có độ tương đồng cao nhất trong kho dữ liệu với ảnh nhận đầu vào và sau đó dự đoán tư thế tương đối giữa chúng để lấy được tư thế tuyệt đối của ảnh nhận đầu vào. Cho một ảnh $I_a^c$ được chụp từ máy ảnh $c$, thông qua các phương pháp truy xuất ảnh từ kho dữ liệu, chúng ta có được ảnh có độ tương đồng cao nhất $I_b^c$. Nếu có được tư thế chính xác $p_b$ của ảnh $I_b^c$ và tư thế tương đối giữa hai ảnh là $p_{a->b}$, tư thế tuyệt đối $p_a$ của ảnh đầu vào $I_a^c$ có thể được xác định bằng các phép biến đổi toán học.

NNnet \cite{laskar2017camera} là công trình đầu tiên đề xuất một phương pháp hồi quy tư thế tương đối dựa trên truy xuất ảnh. Đầu vào của phương pháp này là một ảnh và một kho dữ liệu ảnh có bao gồm tư thế chính xác. Một tập các cặp ảnh được tận dụng để hồi quy tư thế tương đối thông qua một mạng Siamese với hai nhánh ResNet34 đã được hiệu chỉnh và một hàm mất mát cố định. Ảnh có độ tương đồng gần nhất với ảnh nhận đầu vào có thể được tính toán xác định thông qua bộ trích xuất đặc trưng hình thành bởi nhánh mạng CNN, sau đó tư thế tương đối và tư thế của ảnh trích xuất sẽ kết hợp để tính toán xác định tư thế tuyệt đối của ảnh đầu vào.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{pics/Chapter2/nnet.png}
    \caption{Minh họa kiến trúc mô hình NNet \cite{laskar2017camera}}
\end{figure}

Để giải quyết vấn đề hiệu suất giới hạn của các phương pháp hồi quy tư thế tương đối tiền nhiệm do sử dụng cùng đặc trưng cho cả hai bước truy xuất và hồi quy, CamNet \cite{9008579} đề xuất một quy trình chia làm ba bước: truy xuất thô, truy xuất mịn và hồi quy tư thế. Kiến trúc mô hình được xây dựng dựa trên kiến trúc Siamese với ba nhánh mỗi bước. Kiến trúc thô-sang-mịn này đã mang lại những cải tiến về hiệu suất hồi quy cũng như khả năng mở rộng. Hàm mất mát của CamNet lấy ý tưởng dựa trên RelocNet, được định nghĩa như sau:
\begin{center}
    $l = l_{frustum} + l_{angle} + l_{triplet} + l_{PFR} + l_{PRP}$
\end{center}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{pics/Chapter2/camnet.png}
    \caption{Minh họa kiến trúc mô hình CamNet \cite{9008579}}
\end{figure}
Qunjie Zhou và những cộng sự \cite{zhou2020learn} sau khi phân tích các phương pháp hồi quy tư thế dựa trên việc truy xuất ảnh đã đề xuất một kiến trúc mới sử dụng ma trận thiết yếu và RANSAC để tính toán tư thế tuyệt đối. Một mạng Siamese ResNet34 với một lớp tìm sự tương ứng cố định (EssNet) và một lớp tìm sự tương ứng đồng thuận lân cận (NC-EssNet) được học để tạo ra một bản đồ điểm tương ứng phục vụ cho mục đích hồi quy về sau của ma trận thiết yếu. Hàm mất mát cải tiến khoảng cách Euclidean giữa ma trận thiết yếu với hai véc-tơ 9 chiều.
\begin{center}
    $l_{ess}(E^*, E) = \left \| e - e^* \right \|_2$
\end{center}
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{pics/Chapter2/essnet.png}
    \caption{Minh họa kiến trúc mô hình EssNet \cite{zhou2020learn}}
\end{figure}

\subsubsection*{Hồi quy tư thế tương đối thông qua mạng CNN ngầm - Relative camera pose regression through implicit CNN}
Để tránh việc phải thu thập và xây dựng một kho dữ liệu khổng lồ cũng như tốn kém thời gian thử nghiệm, một số phương pháp tìm cách hồi quy tư thế tương đối của máy ảnh thông qua một CNN ngầm.

Relative NN \cite{melekhov2017relative} đề xuất một phương pháp đầu-cuối để hồi quy tư thế tương đối giữa hai máy ảnh bằng hai ảnh đầu vào. Kiến trúc mô hình là một mạng Nơ-ron hỗn hợp Siamese hai nhánh sử dụng mạng AlexNet đã được huấn luyện từ trước được dùng cho việc hồi quy với hàm mất mát Euclidean cố định.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{pics/Chapter2/relativenn.png}
    \caption{Minh họa kiến trúc mô hình Relative Neural Network \cite{melekhov2017relative}}
\end{figure}

Nhận thấy các phương pháp định vị trực quan (Visual Relocalization) hiện tại đều cần một kho dữ liệu ảnh khổng lồ, \cite{arnold2022mapfree} đề xuất phương pháp mang tên "Tái định vị không cần bản đồ (Map-free Relocalization)" với việc chỉ sử dụng duy nhất một ảnh làm đại diện cho một cảnh. \cite{arnold2022mapfree} đã đề xuất hai phương pháp khác nhau để có thể xác định vị trí, góc quay chính xác từ một ảnh: thứ nhất là áp dụng tác vụ khớp đặc trưng kết hợp dự đoán độ sâu để tính toán tư thế tương đối, thứ hai là hồi quy tư thế tương đối dùng một mô hình học sâu đầu-cuối.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{pics/Chapter2/mapfreeFMDE}
    \caption{Minh họa kiến trúc mô hình hồi quy tư thế tương đối của Map-free \cite{arnold2022mapfree}}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{pics/Chapter2/mapfreeRPR}
    \caption{Minh họa kiến trúc mô hình hồi quy tư thế tương đối đầu-cuối của Map-free \cite{arnold2022mapfree}}
\end{figure}

\subsubsection*{Kết luận}
Để thực hiện tác vụ hồi quy tư thế tương đối, một số phương pháp chọn cách tận dụng một quy trình nhiều bước để thu được tư thế tuyệt đối với bước truy xuất ảnh làm trọng tâm \cite{laskar2017camera, 10.1007/978-3-030-01264-9_46, 9008579, zhou2020learn}. NNnet \cite{laskar2017camera} là công trình đầu tiên đề xuất một phương pháp hồi quy tư thế tương đối dựa trên truy xuất ảnh. CamNet \cite{9008579} đề xuất một quy trình chia làm ba bước: truy xuất thô, truy xuất mịn và hồi quy tư thế với ba nhánh CNN mỗi bước và đã mang lại những cải tiến về hiệu suất hồi quy cũng như khả năng mở rộng.

Trong khi đó các phương pháp dựa trên CNN \cite{melekhov2017relative, saha2018improved, arnold2022mapfree} lại đề xuất một hướng giải quyết để hồi quy trực tiếp tư thế tương đối ngay trong mạng nơ-ron. Relative NN \cite{melekhov2017relative} đề xuất một mô hình đầu-cuối Siamese hai nhánh để hồi quy tư thế tương đối giữa hai ảnh đầu vào. Map-free \cite{arnold2022mapfree} đề xuất việc dùng duy nhất một ảnh đại diện cho một địa điểm, đồng thời đề xuất một quy trình hồi quy tư thế tương đối không phụ thuộc vào huấn luyện.

\section{Phân tích và tổng hợp}

\subsection*{Nhận diện địa điểm trực quan}

Khi xem xét những kết quả nghiên cứu trên lĩnh vực nhận diện địa điểm trực quan, các mô hình đã dần phát triển từ việc sử dụng những đặc trưng cục bộ/toàn cục, được biểu diễn bằng những giải thuật được thiết kế tay cho đến việc sử dụng những mạng kết nối đầy đủ hoặc mạng tích chập để có thể học được những đặc trưng một cách tự động và có hiệu quả cao trên những môi trường khác nhau(từ VLAD $\rightarrow$ NetVLAD). Ứng dụng phương pháp học sâu vào hướng tiếp cận này giúp cho những mô hình có phạm vi hoạt động được mở rộng hơn một cách đáng kể trong khi tác động đến tài nguyên phát triển và duy trì thấp. Đây là một điểm mạnh nổi bật, cho phép các mô hình có thể được áp dụng rộng rãi, nhanh chóng và dễ dàng duy trì trong thực tế.
Vì vậy nên, chúng tôi cho rằng các mô hình giải quyết bài toán nhận diện địa điểm trực quan là một hướng đi phù hợp và có tiềm năng để hoàn thành mục tiêu đề ra cho báo cáo. 

% Nhận xét những kết quả tổng hợp được từ các bài báo khoa học từ những ngày đầu phát triển của bài toán nhận diện địa điểm trực quan, có thể thấy, bài toán đã được đặt trong giới hạn dữ liệu (dữ liệu ảnh RGB thuần, không có độ sâu) mang tính chất quyết định đến khả năng xây dựng, phát triển và duy trì hoạt động của các mô hình trước phạm vi dữ liệu lớn về không gian, thời gian và các miền khác. Tất cả các nỗ lực nghiên cứu đến nay đều đang hướng đến việc gia tăng hiệu năng của các mô hình để cạnh tranh với các mô hình không chịu giới hạn.

Gần đây, TransVPR \cite{wang2022transvpr} kết hợp Convolutional Neural Networks (CNN) và Transformers \cite{vaswani2023attention} bằng cách sử dụng cơ chế tự tập trung multi-head như một Transformer encoder trên một CNN cơ sở với mục đích tích hợp thông tin toàn cục vào các token kết quả của mạng Transformer, đánh đổi độ chính xác và độ bền cho kích thước kiến trúc. MixVPR \cite{alibey2023mixvpr} đề xuất sử dụng các khối Feature Mixer nhằm giảm thiểu kích thước và sự ràng buộc của hiệu suất vào cơ chế tập trung trong khi vẫn duy trì độ chính xác và độ bền. AnyLoc \cite{keetha2023anyloc} hướng đến việc tạo ra một giải pháp toàn diện cho VPR bằng cách kết hợp đầu ra của nhiều mô hình cơ sở đã được huấn luyện trước, cách tiếp cận này cho phép họ thực hiện định vị trong cả môi trường có cấu trúc và không có cấu trúc.

AnyLoc \cite{keetha2023anyloc} có độ linh hoạt và khái quát hóa cao do có thể sử dụng trên mọi dạng địa hình ở mọi thời điểm mà không cần tiêu tốn tài nguyên huấn luyện do sử dụng các mô hình cơ sở đã được huấn luyện trước. Tuy nhiên, mô hình này tiêu tốn tài nguyên lớn vào giai đoạn thực thi do lượng lớn tính toán cần thực thi, cũng như công sức để có thể thiết kế ra bộ từ vựng nhằm sử dụng cho những nhóm môi trường khác nhau, đòi hỏi thời gian, cũng như sức lực con người. Mặc khác, MixVPR \cite{alibey2023mixvpr} tuy cần phải huấn luyện trên một tập dữ liệu lớn là GSV-Cities \cite{Ali_bey_2022}, lại có độ khái quát hóa cao khi áp dụng trên các tập dữ liệu thành thị khác (độ chính xác đo trên r@k vượt trên AnyLoc trên tập Pittsburgh250k \cite{6618963}) cũng như tiêu tốn ít tài nguyên hơn hẳn khi thực thi. Sau khi phân tích và so sánh các điểm mạnh và điểm yếu, chúng tôi xác định MixVPR \cite{alibey2023mixvpr} là mô hình phù hợp để làm mô hình cơ sở cho kiến trúc mà chúng tôi đề xuất ở \textbf{Phương pháp đề xuất}.

\subsection*{Hồi quy tư thế}

Đối với những mô hình hồi quy tư thế tuyệt đối, những cột mốc trong không gian tham khảo có thể được xác định ngầm và lưu lại bên trong những trọng số của mô hình. Vì vậy, quá trình hồi quy của mô hình thuộc nhóm này chỉ yêu cầu đầu vào là ảnh truy vấn để dự đoán tư thế cuối cùng. Tuy trong khoảng thời gian gần đây đã xuất hiện nhiều hướng cải tiến mới như tích hợp thêm thông tin về ảnh truy vấn, cải thiện về hàm loss, ứng dụng những công nghệ mạnh hơn như cơ chế tập trung vào mô hình nhằm cải thiện hiệu quả, những mô hình thuộc nhóm này vẫn đang gặp những hạn chế như thiếu khả năng tổng quát hóa, mô hình bị quá khớp trên tập không gian mẫu \cite{sattler2019understanding}. Chúng tôi nhận thấy đây không phải hướng tiếp cận phù hợp với các mục tiêu đề ra của mình.

Các mô hình hồi quy tương đối sẽ trích xuất những cột mốc từ đầu vào, dưới dạng ảnh tham khảo được cho là tương đồng nhất với ảnh truy vấn, từ đó xác định được độ lệch về tư thế giữa hai ảnh và tính toán tư thế của ảnh truy vấn. Nhóm những mô hình sử dụng hướng tiếp cận này thường tập trung vào tác vụ tìm kiếm mối tương quan giữa cặp ảnh, 2D-2D hoặc 2D-3D. Trước đây, khi được tiếp cận theo những phương pháp học sâu, những nghiên cứu đã có những phát hiện về sự thất bại trong việc thực hiện tác vụ Feature Matching giữa hai hình một cách nội hàm bên trong mô hình, từ đó gây ra sai lệch ở kết quả \cite{zhou2020learn}. Gần đây, bài nghiên cứu Map-free \cite{arnold2022mapfree} đề xuất nhiều hướng tiếp cận thú vị cho bài toán: 3D-3D (sử dụng quy trình Procrustes), 2D-3D (sử dụng thuật toán Perspective-n-Point) và 2D-2D (sử dụng ma trận thiết yếu và khai thác độ sâu) nhằm giải quyết tình huống định vị trong một khu vực có ảnh truy vấn ở nhiều góc nhìn đa dạng và chỉ một ảnh tham khảo. Tình huống này giúp phần nào mô phỏng được môi trường định vị trong thành thị, khi mà độ bao phủ của tập dữ liệu tham khảo sẽ thưa hơn, dẫn đến tình huống ảnh tham khảo và ảnh truy vấn có sai lệch đáng kể. Trong những nhóm mô hình được đề xuất bởi \cite{arnold2022mapfree}, chúng tôi quyết định sử dụng hướng tiếp cận 2D-2D nhờ vào kết quả vượt trội so với những mô hình còn lại và không cần huấn luyện. Mô hình sẽ được phân tích kỹ hơn tại \textbf{Phương pháp đề xuất}


% Khi cân nhắc hiệu suất cao của quá trình tính toán tư thế tương đối dựa vào ma trận thiết yếu so với quá trình hồi quy trực tiếp \cite{sattler2019understanding}, có thể thấy được tiềm năng phát triển mới cho bài toán định vị trực quan. Đồng thời, quy trình khai thác ma trận thiết yếu có thể được hiện thực thông qua thuật toán giải 5-điểm (5-Point Solver) \cite{nister2004efficient}, giải pháp này cũng gỡ bỏ một phần gánh nặng của quá trình huấn luyện. Sau khi phân tích, chúng tôi tin rằng, hướng tiếp cận 2D-2D Map-free có tiềm năng hỗ trợ tốt quá trình định vị trực quan cho giải pháp của chúng tôi đề xuất, chi tiết sẽ được nêu rõ hơn .



% Nếu xem xét bài toán định vị trực quan dưới góc nhìn là quy trình hai bước: từ ảnh truy vấn, tìm ảnh truy xuất gần nhất và từ cặp ảnh này, tìm tư thế, vị trí của thiết bị chụp ảnh truy vấn, hiệu năng của bước thứ hai phụ thuộc vào khả năng khai thác các đặc trưng tương quan về góc chụp và thông số thiết bị. Nhận thấy các mô hình hồi quy tư thế tuyệt đối thường xuyên gặp vấn đề quá khớp và thiếu tính khái quát, chúng tôi hướng sự tập trung của mình đến các mô hình hồi quy tư thế tương đối.
